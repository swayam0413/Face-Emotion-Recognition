{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/muxspace/facial_expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d0d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data = {}\n",
    "with open('./facial_expressions/data/legend.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        key = row[2].lower()\n",
    "        if key in data:\n",
    "            data[key].append(row[1])\n",
    "        else:\n",
    "            data[key] = [row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66302864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'sadness',\n",
       " 'contempt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_emotions = list(data.keys())\n",
    "list_of_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875e2ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger 252\n",
      "surprise 368\n",
      "disgust 208\n",
      "fear 21\n",
      "neutral 6868\n",
      "happiness 5696\n",
      "sadness 268\n",
      "contempt 9\n"
     ]
    }
   ],
   "source": [
    "for e, i in data.items():\n",
    "    print(e, len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d02abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('sorted_data')\n",
    "os.mkdir('sorted_data/training')\n",
    "os.mkdir('sorted_data/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957649a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in list_of_emotions:\n",
    "    os.mkdir(os.path.join('sorted_data/training/', emotion))\n",
    "    os.mkdir(os.path.join('sorted_data/testing/', emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e610e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "split_size = 0.8\n",
    "\n",
    "for face_emo, photos in data.items():\n",
    "    train_size = int(split_size*len(photos))\n",
    "    train_images = photos[:train_size]\n",
    "    test_images = photos[train_size:]\n",
    "    \n",
    "    for photo in train_images:\n",
    "        s = os.path.join('./facial_expressions/images', photo)\n",
    "        d = os.path.join('./sorted_data/training', face_emo, photo)\n",
    "        copyfile(s, d)\n",
    "    for photo in test_images:\n",
    "        s = os.path.join('./facial_expressions/images', photo)\n",
    "        d = os.path.join('./sorted_data/testing', face_emo, photo)\n",
    "        copyfile(s, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87a31762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 10:13:16.969579: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e08e3",
   "metadata": {},
   "source": [
    "# Method - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221d3901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 10:13:36.073290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 49, 49, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              6554624   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,586,408\n",
      "Trainable params: 6,586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 10941 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/218315034.py:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 40s 457ms/step - loss: 0.9009 - acc: 0.6324 - val_loss: 1.3300 - val_acc: 0.6360\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 40s 463ms/step - loss: 0.5554 - acc: 0.8087 - val_loss: 1.5537 - val_acc: 0.6689\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 39s 455ms/step - loss: 0.4986 - acc: 0.8261 - val_loss: 1.3733 - val_acc: 0.6947\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 40s 467ms/step - loss: 0.4469 - acc: 0.8466 - val_loss: 1.5817 - val_acc: 0.6867\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 42s 492ms/step - loss: 0.4282 - acc: 0.8529 - val_loss: 1.7734 - val_acc: 0.6718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139ca95b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "      Conv2D(16, (3,3), activation='relu', input_shape = (100, 100, 3)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(32, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(64, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Flatten(),\n",
    "      Dense(1024, activation='relu'),\n",
    "      Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "train_dir = './sorted_data/training'\n",
    "test_dir = './sorted_data/testing'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                    train_dir,\n",
    "                                                    target_size = (100, 100),\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    batch_size = 128\n",
    "                                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    test_dir,\n",
    "                                                    target_size = (100, 100),\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    batch_size = 128\n",
    "                                                  )\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    validation_data = test_generator,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ebf77",
   "metadata": {},
   "source": [
    "# Method - 2 - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56a491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 49, 49, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              6554624   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,586,408\n",
      "Trainable params: 6,586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 10941 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/3543237801.py:50: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "342/342 [==============================] - 99s 287ms/step - loss: 1.0053 - acc: 0.4977 - val_loss: 1.7377 - val_acc: 0.4788\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 78s 229ms/step - loss: 0.9747 - acc: 0.5037 - val_loss: 1.8217 - val_acc: 0.4880\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 81s 236ms/step - loss: 0.9680 - acc: 0.5145 - val_loss: 2.5707 - val_acc: 0.4001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13aae7400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "      Conv2D(16, (3,3), activation='relu', input_shape = (100, 100, 3)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(32, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(64, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Flatten(),\n",
    "      Dense(1024, activation='relu'),\n",
    "      Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100, 100),\n",
    "    class_mode='categorical',\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100, 100),\n",
    "    class_mode='categorical',\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    validation_data = test_generator,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a48a8a",
   "metadata": {},
   "source": [
    "# Method - 3 - Increasing Model Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd10a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 49, 49, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 23, 23, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 10, 10, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               6554112   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,651,464\n",
      "Trainable params: 6,651,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 10941 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/186797225.py:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 89s 1s/step - loss: 0.9969 - acc: 0.5612 - val_loss: 1.7051 - val_acc: 0.6324\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 95s 1s/step - loss: 0.6277 - acc: 0.7880 - val_loss: 1.7437 - val_acc: 0.6605\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 79s 919ms/step - loss: 0.5385 - acc: 0.8187 - val_loss: 1.4469 - val_acc: 0.6823\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 75s 875ms/step - loss: 0.4671 - acc: 0.8402 - val_loss: 1.7576 - val_acc: 0.6798\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 76s 879ms/step - loss: 0.4272 - acc: 0.8532 - val_loss: 1.5365 - val_acc: 0.6915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13aae79a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "      Conv2D(32, (3,3), activation='relu', input_shape = (100, 100, 3)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(64, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(128, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Flatten(),\n",
    "      Dense(512, activation='relu'),\n",
    "      Dropout(0.5),\n",
    "      Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    validation_data = test_generator,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162727ca",
   "metadata": {},
   "source": [
    "# Method - 4 : Add Regularization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "858ac739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 49, 49, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              6554624   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,586,408\n",
      "Trainable params: 6,586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 10941 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/1579458053.py:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 50s 572ms/step - loss: 0.9849 - acc: 0.5797 - val_loss: 1.5588 - val_acc: 0.5759\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 41s 479ms/step - loss: 0.6420 - acc: 0.7863 - val_loss: 1.3889 - val_acc: 0.6492\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 40s 459ms/step - loss: 0.5458 - acc: 0.8202 - val_loss: 1.3409 - val_acc: 0.6721\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 49s 566ms/step - loss: 0.5024 - acc: 0.8344 - val_loss: 1.3549 - val_acc: 0.6864\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 43s 496ms/step - loss: 0.4665 - acc: 0.8427 - val_loss: 1.7084 - val_acc: 0.6659\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 47s 549ms/step - loss: 0.4200 - acc: 0.8564 - val_loss: 1.7731 - val_acc: 0.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13b595070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "      Conv2D(16, (3,3), activation='relu', input_shape = (100, 100, 3)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(32, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(64, (3,3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Flatten(),\n",
    "      Dense(1024, activation='relu'),\n",
    "      Dropout(0.5),\n",
    "      Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    validation_data = test_generator,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad915ec0",
   "metadata": {},
   "source": [
    "# Method - 5 : Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f592be3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 49, 49, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              6554624   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,586,408\n",
      "Trainable params: 6,586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 10941 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/1001216397.py:46: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 41s 470ms/step - loss: 0.9200 - acc: 0.6060 - val_loss: 1.2277 - val_acc: 0.6400 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 40s 463ms/step - loss: 0.5794 - acc: 0.8034 - val_loss: 1.4076 - val_acc: 0.6721 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 40s 463ms/step - loss: 0.4984 - acc: 0.8302 - val_loss: 1.6144 - val_acc: 0.6554 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 41s 474ms/step - loss: 0.4408 - acc: 0.8479 - val_loss: 1.4307 - val_acc: 0.6674 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 48s 553ms/step - loss: 0.4062 - acc: 0.8603 - val_loss: 2.0637 - val_acc: 0.6732 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 49s 567ms/step - loss: 0.3668 - acc: 0.8721 - val_loss: 2.1731 - val_acc: 0.6776 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 53s 621ms/step - loss: 0.3341 - acc: 0.8828 - val_loss: 1.8537 - val_acc: 0.6798 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 50s 585ms/step - loss: 0.3047 - acc: 0.8882 - val_loss: 2.0712 - val_acc: 0.6864 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 50s 581ms/step - loss: 0.2625 - acc: 0.9052 - val_loss: 3.0365 - val_acc: 0.6791 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 42s 483ms/step - loss: 0.2290 - acc: 0.9145 - val_loss: 2.5705 - val_acc: 0.6681 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ba5c880>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "      Conv2D(16, (3,3), activation='relu', input_shape = (100, 100, 3)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(32, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(64, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Flatten(),\n",
    "      Dense(1024, activation='relu'),\n",
    "      Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    validation_data = test_generator,\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d2777",
   "metadata": {},
   "source": [
    "# Method - 6 : Different Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a62363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 49, 49, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              6554624   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,586,408\n",
      "Trainable params: 6,586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 10941 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/3704869186.py:37: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 48s 548ms/step - loss: 1.0815 - acc: 0.4975 - val_loss: 0.9925 - val_acc: 0.5777\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 45s 518ms/step - loss: 0.8499 - acc: 0.6638 - val_loss: 1.6475 - val_acc: 0.6134\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 41s 473ms/step - loss: 0.6653 - acc: 0.7639 - val_loss: 1.8012 - val_acc: 0.6357\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 45s 523ms/step - loss: 0.5782 - acc: 0.7987 - val_loss: 1.6320 - val_acc: 0.6579\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 46s 530ms/step - loss: 0.5423 - acc: 0.8089 - val_loss: 0.9542 - val_acc: 0.6441\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 42s 493ms/step - loss: 0.4763 - acc: 0.8326 - val_loss: 2.0522 - val_acc: 0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13b30b310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "      Conv2D(16, (3,3), activation='relu', input_shape = (100, 100, 3)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(32, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(64, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Flatten(),\n",
    "      Dense(1024, activation='relu'),\n",
    "      Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience = 2, min_delta=0.01)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    validation_data = test_generator,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0fdad",
   "metadata": {},
   "source": [
    "# Method - 7 : Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a5f560c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 49, 49, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1024)              6554624   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,586,408\n",
      "Trainable params: 6,586,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 10941 images belonging to 8 classes.\n",
      "Found 2742 images belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/118832629.py:39: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 38s 422ms/step - loss: 0.8620 - acc: 0.6673 - val_loss: 1.5250 - val_acc: 0.6415\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 48s 560ms/step - loss: 0.5861 - acc: 0.7993 - val_loss: 1.8277 - val_acc: 0.6670\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 40s 464ms/step - loss: 0.4961 - acc: 0.8286 - val_loss: 1.8800 - val_acc: 0.6674\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 41s 476ms/step - loss: 0.4545 - acc: 0.8420 - val_loss: 1.6946 - val_acc: 0.6823\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 41s 472ms/step - loss: 0.4020 - acc: 0.8600 - val_loss: 1.5827 - val_acc: 0.6845\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 40s 469ms/step - loss: 0.3680 - acc: 0.8714 - val_loss: 2.3603 - val_acc: 0.6780\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 39s 454ms/step - loss: 0.3201 - acc: 0.8879 - val_loss: 2.3485 - val_acc: 0.6645\n",
      "<keras.callbacks.History object at 0x13c365310>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "      Conv2D(16, (3,3), activation='relu', input_shape = (100, 100, 3)),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(32, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Conv2D(64, (3,3), activation='relu'),\n",
    "      MaxPooling2D(2, 2),\n",
    "      Flatten(),\n",
    "      Dense(1024, activation='relu'),\n",
    "      Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience = 3, min_delta=0.01)\n",
    "\n",
    "check_point = ModelCheckpoint(filepath='./models/best_model.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    epochs = 10,\n",
    "                    verbose = 1,\n",
    "                    v# VGG16alidation_data = test_generator,\n",
    "                    callbacks = [es, check_point])\n",
    "\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42a36b",
   "metadata": {},
   "source": [
    "# Method 8.1 : Transfer learning - VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "329b49b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1024)              4719616   \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,442,504\n",
      "Trainable params: 4,727,816\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/1084309676.py:30: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 417s 5s/step - loss: 1.1863 - acc: 0.6060 - val_loss: 1.0130 - val_acc: 0.5667 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 421s 5s/step - loss: 0.7753 - acc: 0.6950 - val_loss: 1.0917 - val_acc: 0.5890 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 422s 5s/step - loss: 0.7384 - acc: 0.7111 - val_loss: 1.1530 - val_acc: 0.5646 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 423s 5s/step - loss: 0.7052 - acc: 0.7271 - val_loss: 1.1327 - val_acc: 0.5839 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 425s 5s/step - loss: 0.7373 - acc: 0.7117 - val_loss: 1.1111 - val_acc: 0.6061 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 424s 5s/step - loss: 0.6802 - acc: 0.7390 - val_loss: 1.0836 - val_acc: 0.5875 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 425s 5s/step - loss: 0.6832 - acc: 0.7346 - val_loss: 1.2806 - val_acc: 0.5729 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 426s 5s/step - loss: 0.6718 - acc: 0.7385 - val_loss: 1.3083 - val_acc: 0.5894 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1677e1730>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape=(100, 100, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience=3, min_delta=0.01)\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[es, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5581652",
   "metadata": {},
   "source": [
    "# Method 8.2 : Transfer learning - ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f1c76ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1024)              33555456  \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,151,368\n",
      "Trainable params: 33,563,656\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/565419335.py:30: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 330s 4s/step - loss: 4.2527 - acc: 0.4419 - val_loss: 1.1656 - val_acc: 0.4559 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 289s 3s/step - loss: 1.1727 - acc: 0.4821 - val_loss: 1.4835 - val_acc: 0.4555 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 246s 3s/step - loss: 1.6348 - acc: 0.4780 - val_loss: 1.0601 - val_acc: 0.4351 - lr: 0.0010\n",
      "Epoch 4/10\n",
      " 3/86 [>.............................] - ETA: 3:15 - loss: 1.2806 - acc: 0.4479"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lr \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     28\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m LearningRateScheduler(scheduler)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py:2604\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2593\u001b[0m \n\u001b[1;32m   2594\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2597\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2598\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2602\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2603\u001b[0m )\n\u001b[0;32m-> 2604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(input_shape=(100, 100, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience=3, min_delta=0.01)\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[es, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea636d3c",
   "metadata": {},
   "source": [
    "# Method 8.3 - Transfer Learning ( Inceptionv3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c07d037d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)            (None, 49, 49, 32)   864         ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 49, 49, 32)  96          ['conv2d_247[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_188 (Activation)    (None, 49, 49, 32)   0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)            (None, 47, 47, 32)   9216        ['activation_188[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 47, 47, 32)  96          ['conv2d_248[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_189 (Activation)    (None, 47, 47, 32)   0           ['batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 47, 47, 64)   18432       ['activation_189[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 47, 47, 64)  192         ['conv2d_249[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_190 (Activation)    (None, 47, 47, 64)   0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_63 (MaxPooling2D  (None, 23, 23, 64)  0           ['activation_190[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 23, 23, 80)   5120        ['max_pooling2d_63[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 23, 23, 80)  240         ['conv2d_250[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_191 (Activation)    (None, 23, 23, 80)   0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 21, 21, 192)  138240      ['activation_191[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 21, 21, 192)  576        ['conv2d_251[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_192 (Activation)    (None, 21, 21, 192)  0           ['batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_64 (MaxPooling2D  (None, 10, 10, 192)  0          ['activation_192[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)            (None, 10, 10, 64)   12288       ['max_pooling2d_64[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 10, 10, 64)  192         ['conv2d_255[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_196 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 10, 10, 48)   9216        ['max_pooling2d_64[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)            (None, 10, 10, 96)   55296       ['activation_196[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 10, 10, 48)  144         ['conv2d_253[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 10, 10, 96)  288         ['conv2d_256[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_194 (Activation)    (None, 10, 10, 48)   0           ['batch_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " activation_197 (Activation)    (None, 10, 10, 96)   0           ['batch_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_18 (AverageP  (None, 10, 10, 192)  0          ['max_pooling2d_64[0][0]']       \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 10, 10, 64)   12288       ['max_pooling2d_64[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)            (None, 10, 10, 64)   76800       ['activation_194[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)            (None, 10, 10, 96)   82944       ['activation_197[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)            (None, 10, 10, 32)   6144        ['average_pooling2d_18[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 10, 10, 64)  192         ['conv2d_252[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 10, 10, 64)  192         ['conv2d_254[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 10, 10, 96)  288         ['conv2d_257[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 10, 10, 32)  96          ['conv2d_258[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_193 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " activation_195 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " activation_198 (Activation)    (None, 10, 10, 96)   0           ['batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " activation_199 (Activation)    (None, 10, 10, 32)   0           ['batch_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 10, 10, 256)  0           ['activation_193[0][0]',         \n",
      "                                                                  'activation_195[0][0]',         \n",
      "                                                                  'activation_198[0][0]',         \n",
      "                                                                  'activation_199[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 10, 10, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 10, 10, 64)  192         ['conv2d_262[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)            (None, 10, 10, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 10, 10, 96)   55296       ['activation_203[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 10, 10, 48)  144         ['conv2d_260[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 10, 10, 96)  288         ['conv2d_263[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_201 (Activation)    (None, 10, 10, 48)   0           ['batch_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 10, 10, 96)   0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_19 (AverageP  (None, 10, 10, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)            (None, 10, 10, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)            (None, 10, 10, 64)   76800       ['activation_201[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 10, 10, 96)   82944       ['activation_204[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 10, 10, 64)   16384       ['average_pooling2d_19[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 10, 10, 64)  192         ['conv2d_259[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 10, 10, 64)  192         ['conv2d_261[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 10, 10, 96)  288         ['conv2d_264[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 10, 10, 64)  192         ['conv2d_265[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_200 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " activation_202 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 10, 10, 96)   0           ['batch_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 10, 10, 288)  0           ['activation_200[0][0]',         \n",
      "                                                                  'activation_202[0][0]',         \n",
      "                                                                  'activation_205[0][0]',         \n",
      "                                                                  'activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 10, 10, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 10, 10, 64)  192         ['conv2d_269[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_210 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 10, 10, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 10, 10, 96)   55296       ['activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 10, 10, 48)  144         ['conv2d_267[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 10, 10, 96)  288         ['conv2d_270[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 10, 10, 48)   0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 10, 10, 96)   0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_20 (AverageP  (None, 10, 10, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 10, 10, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 10, 10, 64)   76800       ['activation_208[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 10, 10, 96)   82944       ['activation_211[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 10, 10, 64)   18432       ['average_pooling2d_20[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 10, 10, 64)  192         ['conv2d_266[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 10, 10, 64)  192         ['conv2d_268[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 10, 10, 96)  288         ['conv2d_271[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 10, 10, 64)  192         ['conv2d_272[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 10, 10, 96)   0           ['batch_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 10, 10, 288)  0           ['activation_207[0][0]',         \n",
      "                                                                  'activation_209[0][0]',         \n",
      "                                                                  'activation_212[0][0]',         \n",
      "                                                                  'activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)            (None, 10, 10, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 10, 10, 64)  192         ['conv2d_274[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 10, 10, 64)   0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)            (None, 10, 10, 96)   55296       ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 10, 10, 96)  288         ['conv2d_275[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 10, 10, 96)   0           ['batch_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)            (None, 4, 4, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)            (None, 4, 4, 96)     82944       ['activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 4, 4, 384)   1152        ['conv2d_273[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 4, 4, 96)    288         ['conv2d_276[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 4, 4, 384)    0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 4, 4, 96)     0           ['batch_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_65 (MaxPooling2D  (None, 4, 4, 288)   0           ['mixed2[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " mixed3 (Concatenate)           (None, 4, 4, 768)    0           ['activation_214[0][0]',         \n",
      "                                                                  'activation_217[0][0]',         \n",
      "                                                                  'max_pooling2d_65[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)            (None, 4, 4, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 4, 4, 128)   384         ['conv2d_281[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_282 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_222[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 4, 4, 128)   384         ['conv2d_282[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)            (None, 4, 4, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_283 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 4, 4, 128)   384         ['conv2d_278[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 4, 4, 128)   384         ['conv2d_283[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_284 (Conv2D)            (None, 4, 4, 128)    114688      ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 4, 4, 128)   384         ['conv2d_279[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 4, 4, 128)   384         ['conv2d_284[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 4, 4, 128)    0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_21 (AverageP  (None, 4, 4, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)            (None, 4, 4, 192)    172032      ['activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_285 (Conv2D)            (None, 4, 4, 192)    172032      ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_286 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_21[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 4, 4, 192)   576         ['conv2d_277[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 4, 4, 192)   576         ['conv2d_280[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 4, 4, 192)   576         ['conv2d_285[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 4, 4, 192)   576         ['conv2d_286[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 4, 4, 768)    0           ['activation_218[0][0]',         \n",
      "                                                                  'activation_221[0][0]',         \n",
      "                                                                  'activation_226[0][0]',         \n",
      "                                                                  'activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_291 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed4[0][0]']                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 4, 4, 160)   480         ['conv2d_291[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_292 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 4, 4, 160)   480         ['conv2d_292[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_288 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_293 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 4, 4, 160)   480         ['conv2d_288[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 4, 4, 160)   480         ['conv2d_293[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_289 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_294 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 4, 4, 160)   480         ['conv2d_289[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 4, 4, 160)   480         ['conv2d_294[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_22 (AverageP  (None, 4, 4, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_287 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_290 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_295 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_22[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 4, 4, 192)   576         ['conv2d_287[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 4, 4, 192)   576         ['conv2d_290[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 4, 4, 192)   576         ['conv2d_295[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 4, 4, 192)   576         ['conv2d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 4, 4, 768)    0           ['activation_228[0][0]',         \n",
      "                                                                  'activation_231[0][0]',         \n",
      "                                                                  'activation_236[0][0]',         \n",
      "                                                                  'activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 4, 4, 160)   480         ['conv2d_301[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_242[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 4, 4, 160)   480         ['conv2d_302[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 4, 4, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 4, 4, 160)   480         ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_244 (Batch  (None, 4, 4, 160)   480         ['conv2d_303[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)            (None, 4, 4, 160)    179200      ['activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 4, 4, 160)   480         ['conv2d_299[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_245 (Batch  (None, 4, 4, 160)   480         ['conv2d_304[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 4, 4, 160)    0           ['batch_normalization_245[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_23 (AverageP  (None, 4, 4, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_240[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)            (None, 4, 4, 192)    215040      ['activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_23[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 4, 4, 192)   576         ['conv2d_297[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 4, 4, 192)   576         ['conv2d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_246 (Batch  (None, 4, 4, 192)   576         ['conv2d_305[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 4, 4, 192)   576         ['conv2d_306[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 4, 4, 768)    0           ['activation_238[0][0]',         \n",
      "                                                                  'activation_241[0][0]',         \n",
      "                                                                  'activation_246[0][0]',         \n",
      "                                                                  'activation_247[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 4, 4, 192)   576         ['conv2d_311[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_252[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 4, 4, 192)   576         ['conv2d_312[0][0]']             \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_253[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_253[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 4, 4, 192)   576         ['conv2d_308[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 4, 4, 192)   576         ['conv2d_313[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_249[0][0]']\n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 4, 4, 192)   576         ['conv2d_309[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 4, 4, 192)   576         ['conv2d_314[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_24 (AverageP  (None, 4, 4, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)            (None, 4, 4, 192)    147456      ['average_pooling2d_24[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 4, 4, 192)   576         ['conv2d_307[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 4, 4, 192)   576         ['conv2d_310[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 4, 4, 192)   576         ['conv2d_315[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 4, 4, 192)   576         ['conv2d_316[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_251[0][0]']\n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 4, 4, 768)    0           ['activation_248[0][0]',         \n",
      "                                                                  'activation_251[0][0]',         \n",
      "                                                                  'activation_256[0][0]',         \n",
      "                                                                  'activation_257[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_319 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 4, 4, 192)   576         ['conv2d_319[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_260 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_320 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_260[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 4, 4, 192)   576         ['conv2d_320[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_261 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_317 (Conv2D)            (None, 4, 4, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_321 (Conv2D)            (None, 4, 4, 192)    258048      ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_258 (Batch  (None, 4, 4, 192)   576         ['conv2d_317[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 4, 4, 192)   576         ['conv2d_321[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_258 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " activation_262 (Activation)    (None, 4, 4, 192)    0           ['batch_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_318 (Conv2D)            (None, 1, 1, 320)    552960      ['activation_258[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_322 (Conv2D)            (None, 1, 1, 192)    331776      ['activation_262[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 1, 1, 320)   960         ['conv2d_318[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 1, 1, 192)   576         ['conv2d_322[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_259 (Activation)    (None, 1, 1, 320)    0           ['batch_normalization_259[0][0]']\n",
      "                                                                                                  \n",
      " activation_263 (Activation)    (None, 1, 1, 192)    0           ['batch_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_66 (MaxPooling2D  (None, 1, 1, 768)   0           ['mixed7[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 1, 1, 1280)   0           ['activation_259[0][0]',         \n",
      "                                                                  'activation_263[0][0]',         \n",
      "                                                                  'max_pooling2d_66[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_327 (Conv2D)            (None, 1, 1, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_268 (Batch  (None, 1, 1, 448)   1344        ['conv2d_327[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_268 (Activation)    (None, 1, 1, 448)    0           ['batch_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_324 (Conv2D)            (None, 1, 1, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_328 (Conv2D)            (None, 1, 1, 384)    1548288     ['activation_268[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_265 (Batch  (None, 1, 1, 384)   1152        ['conv2d_324[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_269 (Batch  (None, 1, 1, 384)   1152        ['conv2d_328[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_265 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_265[0][0]']\n",
      "                                                                                                  \n",
      " activation_269 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_325 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_326 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_265[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_329 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_269[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_330 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_269[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_25 (AverageP  (None, 1, 1, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_323 (Conv2D)            (None, 1, 1, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_266 (Batch  (None, 1, 1, 384)   1152        ['conv2d_325[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_267 (Batch  (None, 1, 1, 384)   1152        ['conv2d_326[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 1, 1, 384)   1152        ['conv2d_329[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 1, 1, 384)   1152        ['conv2d_330[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_331 (Conv2D)            (None, 1, 1, 192)    245760      ['average_pooling2d_25[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 1, 1, 320)   960         ['conv2d_323[0][0]']             \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_266 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " activation_267 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " activation_270 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " activation_271 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 1, 1, 192)   576         ['conv2d_331[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_264 (Activation)    (None, 1, 1, 320)    0           ['batch_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 1, 1, 768)    0           ['activation_266[0][0]',         \n",
      "                                                                  'activation_267[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1, 1, 768)    0           ['activation_270[0][0]',         \n",
      "                                                                  'activation_271[0][0]']         \n",
      "                                                                                                  \n",
      " activation_272 (Activation)    (None, 1, 1, 192)    0           ['batch_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 1, 1, 2048)   0           ['activation_264[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_4[0][0]',          \n",
      "                                                                  'activation_272[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_336 (Conv2D)            (None, 1, 1, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 1, 1, 448)   1344        ['conv2d_336[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_277 (Activation)    (None, 1, 1, 448)    0           ['batch_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_333 (Conv2D)            (None, 1, 1, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_337 (Conv2D)            (None, 1, 1, 384)    1548288     ['activation_277[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 1, 1, 384)   1152        ['conv2d_333[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 1, 1, 384)   1152        ['conv2d_337[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_274 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " activation_278 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_334 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_335 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_274[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_338 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_339 (Conv2D)            (None, 1, 1, 384)    442368      ['activation_278[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_26 (AverageP  (None, 1, 1, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_332 (Conv2D)            (None, 1, 1, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 1, 1, 384)   1152        ['conv2d_334[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 1, 1, 384)   1152        ['conv2d_335[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_279 (Batch  (None, 1, 1, 384)   1152        ['conv2d_338[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_280 (Batch  (None, 1, 1, 384)   1152        ['conv2d_339[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_340 (Conv2D)            (None, 1, 1, 192)    393216      ['average_pooling2d_26[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 1, 1, 320)   960         ['conv2d_332[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_275 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " activation_276 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " activation_279 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_279[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_280 (Activation)    (None, 1, 1, 384)    0           ['batch_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_281 (Batch  (None, 1, 1, 192)   576         ['conv2d_340[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_273 (Activation)    (None, 1, 1, 320)    0           ['batch_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 1, 1, 768)    0           ['activation_275[0][0]',         \n",
      "                                                                  'activation_276[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 1, 1, 768)    0           ['activation_279[0][0]',         \n",
      "                                                                  'activation_280[0][0]']         \n",
      "                                                                                                  \n",
      " activation_281 (Activation)    (None, 1, 1, 192)    0           ['batch_normalization_281[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 1, 1, 2048)   0           ['activation_273[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_5[0][0]',          \n",
      "                                                                  'activation_281[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_22 (Flatten)           (None, 2048)         0           ['mixed10[0][0]']                \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 1024)         2098176     ['flatten_22[0][0]']             \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 8)            8200        ['dense_47[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,909,160\n",
      "Trainable params: 2,106,376\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/1963490440.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 101s 1s/step - loss: 1.2083 - acc: 0.5688 - val_loss: 1.2841 - val_acc: 0.4292 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 86s 1s/step - loss: 0.9048 - acc: 0.6131 - val_loss: 1.2038 - val_acc: 0.5124 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 86s 997ms/step - loss: 0.8819 - acc: 0.6216 - val_loss: 1.3546 - val_acc: 0.5292 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 86s 994ms/step - loss: 0.8708 - acc: 0.6313 - val_loss: 1.2419 - val_acc: 0.5058 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 86s 996ms/step - loss: 0.8513 - acc: 0.6394 - val_loss: 1.4105 - val_acc: 0.5029 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 86s 1s/step - loss: 0.8418 - acc: 0.6468 - val_loss: 1.6597 - val_acc: 0.5310 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16a5e3f10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_model = InceptionV3(include_top=False, input_shape=(100, 100, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "output = Dense(8, activation='softmax')(x)\n",
    "\n",
    "model = Model(base_model.input, output)\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', patience=3, min_delta=0.01)\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[es, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63dbda5",
   "metadata": {},
   "source": [
    "# Method - 8.4 : Transfer Learning (MobileNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c8e8e59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 50, 50, 32)        864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 50, 50, 32)       128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 50, 50, 32)        0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 50, 50, 32)       288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 50, 50, 32)       128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 50, 50, 32)        0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 50, 50, 64)        2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 50, 50, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 51, 51, 64)        0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 25, 25, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 25, 25, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 25, 25, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 25, 25, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 25, 25, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 25, 25, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 12, 12, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 12, 12, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 12, 12, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 12, 12, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 12, 12, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 12, 12, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 13, 13, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 6, 6, 256)        2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 6, 6, 256)        1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 6, 6, 512)         131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 6, 6, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 6, 6, 512)         262144    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 6, 6, 512)        4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 6, 6, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 6, 6, 512)        2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 6, 6, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 6, 6, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 6, 6, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 6, 6, 512)         262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 6, 6, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 7, 7, 512)        0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 3, 3, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 3, 3, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 3, 3, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 3, 3, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 3, 3, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 3, 3, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 3, 3, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 8)                 8200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,286,664\n",
      "Trainable params: 1,057,800\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/np1xc13x3fsf33wqh8hwp3fr0000gn/T/ipykernel_5769/715175190.py:44: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "86/86 [==============================] - 71s 813ms/step - loss: 1.0870 - acc: 0.6774 - val_loss: 1.0961 - val_acc: 0.6050 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 69s 800ms/step - loss: 0.7135 - acc: 0.7294 - val_loss: 1.1677 - val_acc: 0.6072 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 68s 795ms/step - loss: 0.6795 - acc: 0.7434 - val_loss: 1.3965 - val_acc: 0.6036 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 68s 790ms/step - loss: 0.6544 - acc: 0.7561 - val_loss: 1.5991 - val_acc: 0.5835 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1692dc550>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (100, 100, 3)\n",
    "\n",
    "# Create the base MobileNet model\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a classification layer\n",
    "predictions = Dense(8, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the new layers\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "# Set up the early stopping callback\n",
    "es = EarlyStopping(monitor='val_acc', patience=3, min_delta=0.01)\n",
    "\n",
    "# Set up the learning rate scheduler callback\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=test_generator,\n",
    "                    callbacks=[es, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0966bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
